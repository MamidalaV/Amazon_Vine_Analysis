{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"demographics.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"poHAnPg7ZPom","executionInfo":{"status":"ok","timestamp":1623196394220,"user_tz":240,"elapsed":24708,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}},"outputId":"65253ecc-d017-47c1-c9a6-ece0f7c7f32c"},"source":["import os\n","# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.2'\n","spark_version = 'spark-3.1.2'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Connecting to\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Reading package lists... Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-MsDdfvZCnKY","executionInfo":{"status":"ok","timestamp":1623196489395,"user_tz":240,"elapsed":7228,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}}},"source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Demographics\").getOrCreate()"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HT_VAZmzZGqe","executionInfo":{"status":"ok","timestamp":1623196496529,"user_tz":240,"elapsed":7139,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}},"outputId":"1b8960ae-c95b-4bdb-9ddc-72e18c0eb575"},"source":["# Read in data from S3 Buckets\n","from pyspark import SparkFiles\n","url = \"https://s3.amazonaws.com/dataviz-curriculum/day_1/demographics.csv\"\n","spark.sparkContext.addFile(url)\n","df = spark.read.csv(SparkFiles.get(\"demographics.csv\"), sep=\",\", header=True)\n","\n","# Show DataFrame\n","df.show()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["+---+--------------------+---+------------+---------+--------+------------------+---------------+------+-------------+\n","| id|                name|age|height_meter|weight_kg|children|        occupation|academic_degree|salary|     location|\n","+---+--------------------+---+------------+---------+--------+------------------+---------------+------+-------------+\n","|  0|       Darlena Avila| 58|        1.87|       53|       1|     Choreographer|            PhD|    68| South Dakota|\n","|  1|            Yan Boyd| 65|         1.8|       40|       0|         Cellarman|       Bachelor|    73|     Delaware|\n","|  2|         Joette Lane| 32|         1.8|       73|       1|Veterinary Surgeon|         Master|    69| South Dakota|\n","|  3|        Jazmine Hunt| 61|        1.79|       89|       0|            Hawker|            PhD|    88|    Louisiana|\n","|  4|      Remedios Gomez| 23|        1.64|       51|       2|     Choreographer|       Bachelor|    83|West Virginia|\n","|  5|        Myung Brewer| 20|        1.68|       60|       4|    Window Dresser|       Bachelor|    65| South Dakota|\n","|  6|         Shaun Lynch| 31|        1.56|       62|       0|            Weaver|         Master|    72|    Louisiana|\n","|  7|     Melodi Mcdowell| 56|         1.6|       42|       0| Lighthouse Keeper|         Master|    65|    Louisiana|\n","|  8|Charlesetta Steve...| 30|        1.62|       44|       3|        Millwright|         Master|    87|    Louisiana|\n","|  9|       Merri Charles| 44|        1.69|       51|       5|  Medical Supplier|            PhD|    72|West Virginia|\n","| 10|        Cassi Meyers| 55|        1.82|       72|       5|        Manicurist|       Bachelor|    73| South Dakota|\n","| 11|      Shawnee Harmon| 66|        1.63|       78|       5| Medical Physicist|            PhD|    90|     Delaware|\n","| 12|       Lyndia Spears| 62|        1.88|       41|       1|         Assistant|         Master|    78|       Alaska|\n","| 13|          Page Evans| 35|        1.53|       74|       5|         Paramedic|       Bachelor|    69|     Delaware|\n","| 14|        Telma Hebert| 66|        1.94|       79|       3|       Genealogist|         Master|    75| South Dakota|\n","| 15|      Edelmira Drake| 23|        1.87|       72|       2|           Servant|            PhD|    77| South Dakota|\n","| 16|       Oscar Guthrie| 40|        1.61|       46|       4| Technical Liaison|       Bachelor|    76|    Louisiana|\n","| 17|   Bernardina Strong| 34|        1.55|       78|       1|         Scientist|            PhD|    90| South Dakota|\n","| 18|        Caprice Hart| 64|        1.69|       67|       4|   Market Research|            PhD|    79|    Louisiana|\n","| 19|         Alleen Pace| 25|        1.86|       81|       4|  Medical Supplier|            PhD|    77| South Dakota|\n","+---+--------------------+---+------------+---------+--------+------------------+---------------+------+-------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vuhd0Jz_ZTbO","executionInfo":{"status":"ok","timestamp":1623196502492,"user_tz":240,"elapsed":160,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}},"outputId":"c7953b1d-597a-4b9d-88c7-96d80714922c"},"source":["# Print the column names\n","df.columns"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['id',\n"," 'name',\n"," 'age',\n"," 'height_meter',\n"," 'weight_kg',\n"," 'children',\n"," 'occupation',\n"," 'academic_degree',\n"," 'salary',\n"," 'location']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dn0OANoaZWjU","executionInfo":{"status":"ok","timestamp":1623196517197,"user_tz":240,"elapsed":359,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}},"outputId":"92c76b8a-fe22-4a93-e28e-ea185041b383"},"source":["# Print out the first 10 rows\n","df.show(10)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["+---+--------------------+---+------------+---------+--------+------------------+---------------+------+-------------+\n","| id|                name|age|height_meter|weight_kg|children|        occupation|academic_degree|salary|     location|\n","+---+--------------------+---+------------+---------+--------+------------------+---------------+------+-------------+\n","|  0|       Darlena Avila| 58|        1.87|       53|       1|     Choreographer|            PhD|    68| South Dakota|\n","|  1|            Yan Boyd| 65|         1.8|       40|       0|         Cellarman|       Bachelor|    73|     Delaware|\n","|  2|         Joette Lane| 32|         1.8|       73|       1|Veterinary Surgeon|         Master|    69| South Dakota|\n","|  3|        Jazmine Hunt| 61|        1.79|       89|       0|            Hawker|            PhD|    88|    Louisiana|\n","|  4|      Remedios Gomez| 23|        1.64|       51|       2|     Choreographer|       Bachelor|    83|West Virginia|\n","|  5|        Myung Brewer| 20|        1.68|       60|       4|    Window Dresser|       Bachelor|    65| South Dakota|\n","|  6|         Shaun Lynch| 31|        1.56|       62|       0|            Weaver|         Master|    72|    Louisiana|\n","|  7|     Melodi Mcdowell| 56|         1.6|       42|       0| Lighthouse Keeper|         Master|    65|    Louisiana|\n","|  8|Charlesetta Steve...| 30|        1.62|       44|       3|        Millwright|         Master|    87|    Louisiana|\n","|  9|       Merri Charles| 44|        1.69|       51|       5|  Medical Supplier|            PhD|    72|West Virginia|\n","+---+--------------------+---+------------+---------+--------+------------------+---------------+------+-------------+\n","only showing top 10 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8QzpRD8dZdsD","executionInfo":{"status":"ok","timestamp":1623196570481,"user_tz":240,"elapsed":890,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}},"outputId":"0aca8275-a28e-4494-8557-97b5f7fb367a"},"source":["# Select the age, height_meter, and weight_kg columns and use describe to show the summary statistics\n","df['age','height_meter','weight_kg'].describe().show()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["+-------+------------------+------------------+------------------+\n","|summary|               age|      height_meter|         weight_kg|\n","+-------+------------------+------------------+------------------+\n","|  count|              1000|              1000|              1000|\n","|   mean|            42.933|1.7519499999999995|            64.011|\n","| stddev|14.255445581556843|0.1436897499623555|15.005733939099779|\n","|    min|                18|               1.5|                38|\n","|    max|                67|                 2|                90|\n","+-------+------------------+------------------+------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ULIuI1pNZfws","executionInfo":{"status":"ok","timestamp":1623196583777,"user_tz":240,"elapsed":264,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}},"outputId":"d13df812-76d3-4854-d9ea-b40e685e8d8a"},"source":["# Print the schema to see the types\n","df.printSchema()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["root\n"," |-- id: string (nullable = true)\n"," |-- name: string (nullable = true)\n"," |-- age: string (nullable = true)\n"," |-- height_meter: string (nullable = true)\n"," |-- weight_kg: string (nullable = true)\n"," |-- children: string (nullable = true)\n"," |-- occupation: string (nullable = true)\n"," |-- academic_degree: string (nullable = true)\n"," |-- salary: string (nullable = true)\n"," |-- location: string (nullable = true)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iuFP8TEZZhfb","executionInfo":{"status":"ok","timestamp":1623196966749,"user_tz":240,"elapsed":332,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}},"outputId":"7b005194-8e08-4bb4-8035-fae26aec33fa"},"source":["# Rename the Salary column to `Salary (1k)` and show only this new column\n","new_df = df.withColumnRenamed('salary','Salary (1k)')\n","new_df.select('Salary (1k)').show()"],"execution_count":25,"outputs":[{"output_type":"stream","text":["+-----------+\n","|Salary (1k)|\n","+-----------+\n","|         68|\n","|         73|\n","|         69|\n","|         88|\n","|         83|\n","|         65|\n","|         72|\n","|         65|\n","|         87|\n","|         72|\n","|         73|\n","|         90|\n","|         78|\n","|         69|\n","|         75|\n","|         77|\n","|         76|\n","|         90|\n","|         79|\n","|         77|\n","+-----------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":490},"id":"NQyUp2OYZjRM","executionInfo":{"status":"error","timestamp":1623197902061,"user_tz":240,"elapsed":142,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}},"outputId":"5f74aa04-00c3-408e-f6f8-e05cf7c2e364"},"source":["# Create a new column called `Salary` where the values are the `Salary (1k)` * 1000\n","# Show the columns `Salary` and `Salary (1k)`\n","new_df.withColumn('salary', df['salary'] * 1000).select('salary','Salary (1K)').show()\n","\n","#dataframe.withColumn('newprice', dataframe['price']).show()"],"execution_count":28,"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-6f99b83303d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a new column called `Salary` where the values are the `Salary (1k)` * 1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Show the columns `Salary` and `Salary (1k)`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'salary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'salary'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'salary'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Salary (1K)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#dataframe.withColumn('newprice', dataframe['price']).show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2453\u001b[0m         \"\"\"\n\u001b[1;32m   2454\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexisting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.1.2-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: Resolved attribute(s) salary#24 missing from id#16,name#17,age#18,height_meter#19,weight_kg#20,children#21,occupation#22,academic_degree#23,Salary (1k)#759,location#25 in operator !Project [id#16, name#17, age#18, height_meter#19, weight_kg#20, children#21, occupation#22, academic_degree#23, Salary (1k)#759, location#25, (cast(salary#24 as double) * cast(1000 as double)) AS salary#799].;\n!Project [id#16, name#17, age#18, height_meter#19, weight_kg#20, children#21, occupation#22, academic_degree#23, Salary (1k)#759, location#25, (cast(salary#24 as double) * cast(1000 as double)) AS salary#799]\n+- Project [id#16, name#17, age#18, height_meter#19, weight_kg#20, children#21, occupation#22, academic_degree#23, salary#24 AS Salary (1k)#759, location#25]\n   +- Relation[id#16,name#17,age#18,height_meter#19,weight_kg#20,children#21,occupation#22,academic_degree#23,salary#24,location#25] csv\n"]}]},{"cell_type":"code","metadata":{"id":"A_mLR32gE0nN"},"source":[""],"execution_count":null,"outputs":[]}]}