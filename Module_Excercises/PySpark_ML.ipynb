{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PySpark_ML.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNQDOzw4doDm0XT1otRS2lG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"ZXgASWFVM9so","executionInfo":{"status":"ok","timestamp":1623216542192,"user_tz":240,"elapsed":98,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}}},"source":[""],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bg79g-lQZoxe","executionInfo":{"status":"ok","timestamp":1623216589689,"user_tz":240,"elapsed":47393,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}},"outputId":"7e56a297-1844-46eb-80cd-a8a9f8d2efd8"},"source":["import os\n","# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.2'\n","spark_version = 'spark-3.1.2'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()\n","\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/88.7 kB 16%] [Connec\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/88.7 kB 16%] [Waitin\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rHit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:11 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,184 kB]\n","Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,616 kB]\n","Fetched 5,053 kB in 3s (1,659 kB/s)\n","Reading package lists... Done\n","Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Fetched 74.6 kB in 2s (33.6 kB/s)\n","Reading package lists... Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ON5gnjLPNNQT","executionInfo":{"status":"ok","timestamp":1623216589690,"user_tz":240,"elapsed":10,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}}},"source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Tokens\").getOrCreate()"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"3b5A9t1mNcDn","executionInfo":{"status":"ok","timestamp":1623216589690,"user_tz":240,"elapsed":7,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}}},"source":["#import `Tokenizer`\n","from pyspark.ml.feature import Tokenizer"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJCdEnFoNiO1","executionInfo":{"status":"ok","timestamp":1623216800257,"user_tz":240,"elapsed":160,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}},"outputId":"09b01c69-73a9-419d-ac6d-2a5cedc70369"},"source":["#Create sample dataframe\n","dataframe = spark.createDataFrame([\n","                                   (0, \"Spark is great\"),\n","                                   (1, \"We are learning spark\"),\n","                                   (2, \"Spark is better than Hadoop no doubt\")],\n","                                  [\"id\",\"sentence\"])\n","\n","dataframe.show()"],"execution_count":24,"outputs":[{"output_type":"stream","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|      Spark is great|\n","|  1|We are learning s...|\n","|  2|Spark is better t...|\n","+---+--------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AYRUQLJVOKJK","executionInfo":{"status":"ok","timestamp":1623216826396,"user_tz":240,"elapsed":117,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}},"outputId":"1142d93c-43de-4e88-cedb-d43a082ae092"},"source":["#Tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\",outputCol=\"tokenized words\")\n","tokenizer"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tokenizer_3e77b7d8b5fd"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-jiFgk-2PB4i","executionInfo":{"status":"ok","timestamp":1623216828101,"user_tz":240,"elapsed":384,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}},"outputId":"96af1ce7-ecf3-40db-c16a-4a706a8ff45a"},"source":["#Transform and show Dataframe\n","tokenized_df = tokenizer.transform(dataframe)\n","tokenized_df.show(truncate=False)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+--------------------------------------------+\n","|id |sentence                            |tokenized words                             |\n","+---+------------------------------------+--------------------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |\n","|1  |We are learning spark               |[we, are, learning, spark]                  |\n","|2  |Spark is better than Hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|\n","+---+------------------------------------+--------------------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"knWprL9ZPXb6","executionInfo":{"status":"ok","timestamp":1623216927648,"user_tz":240,"elapsed":103,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}}},"source":["# Create a function to return the length of a list\n","def word_list_length(word_list):\n","  return len(word_list)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"wHkUGAoXRLKg","executionInfo":{"status":"ok","timestamp":1623216992677,"user_tz":240,"elapsed":109,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}}},"source":["from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"8aBK_KehRbCY","executionInfo":{"status":"ok","timestamp":1623217044932,"user_tz":240,"elapsed":107,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}}},"source":["# Create a user defined function\n","count_tokens = udf(word_list_length, IntegerType())"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XtRPzu8SRms6","executionInfo":{"status":"ok","timestamp":1623217400819,"user_tz":240,"elapsed":979,"user":{"displayName":"Vinay Mamidala","photoUrl":"","userId":"18417762496406814548"}},"outputId":"003732cd-5e53-4842-c4ef-cf289a242998"},"source":["#create our own tokenizer\n","tokenizer = Tokenizer(inputCol=\"sentence\",outputCol=\"tokenized words\")\n","\n","#Transform DataFrame\n","tokenized_df = tokenizer.transform(dataframe)\n","\n","#select the needed columns and don't truncate results\n","tokenized_df.withColumn(\"tokens\", count_tokens(col(\"tokenized words\"))).show(truncate=False)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+--------------------------------------------+------+\n","|id |sentence                            |tokenized words                             |tokens|\n","+---+------------------------------------+--------------------------------------------+------+\n","|0  |Spark is great                      |[spark, is, great]                          |3     |\n","|1  |We are learning spark               |[we, are, learning, spark]                  |4     |\n","|2  |Spark is better than Hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|7     |\n","+---+------------------------------------+--------------------------------------------+------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bO3vtShyS6bW"},"source":[""],"execution_count":null,"outputs":[]}]}